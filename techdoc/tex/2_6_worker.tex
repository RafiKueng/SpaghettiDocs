\subsection{Worker}
\label{sec:worker}

The actual simulation of the models is done by GLASS.
Since the modeling takes in the order of minutes, a modeling task can not simply be done by the server.
Depending on the server architecture, this would block at least a web server worker thread, making it unable to respond to other requests.
Since the simulation of models is the most CPU intensive task, this needs to be easy scalable, in case more users start to use \spl. 
Preferably, the simulation jobs could be distributed to several machines.

GLASS is a command line application that expects a config file to run on.

For the management of the worker thread Celery was chosen.


\subsubsection{Celery overview}
Celery is distributed task queue implemented in Python.
It offers integration packages for many web frameworks, including Django.
This makes the setup of a distributed task system with Django and Celery easy.

\code{start_task.py}{Example of how to call a task from Django. Simplified version of \F{getSimulationJSON()} from \befn{ModellerApp/views.py}}

Possible units of work, called tasks, can be defined as python function on the server side in Django using the file \befn{/lmt/tasks.py}.
This tasks can be started by Django asynchronously by a call to the task as shown in \lstref{start_task.py} and return a \C{AsyncResult} instance that allows to check the state of the task or it's return value in a next step.

Once a task is started by Django, Celery takes over.
The task is sent to a message broker that implements the task queue.
The celery worker threads then consume the tasks from this queue, process it and save the result back in a result back end. The result backend keeps also track of the tasks states.

All these processes communicate over TCP sockets and thus can run on different machines.

\subsubsection{The tasks}

\code{tasks.py}{Server side definition of worker task. Simplified version of \befn{lmt/tasks.py}}
\code{run_worker.sh}{Shell script representing a task.}

The tasks are defined in \befn{lmt/tasks.py} on the server side.
It's a simple call for a shell script that gets the needed files, calls GLASS, and upload the results back to the servers file system.
See \lstref{tasks.py} for the definition of tasks and \lstref{run_worker.sh} for the called shell file.



\subsubsection{The message broker}

The message brokering is done with RabbitMQ, the recommended task queue backend.
It is open source software written in Erlang, implementing Advanced Message Queueing Protocoll (AMPQ).

\subsubsection{The worker threads}

Worker threads are independent units that can be started on any machine that is able to connect to the message broker. They only need a local install that is a Python with installed Celery module.
Thus it can run on any machine, even with non root access.

Since the worker thread fires up GLASS locally, it needs the config file generated by the server available. The files model state file and plots generated by the simulation then need to be uploaded to the servers media directory again.
This is done using a shell script using \T{wget} for download and \T{scp} for upload, see \lstref{run_worker.sh}.

%\code{run_worker.sh}{Worker script. Gets the config file, fires up GLASS, re uploads the generated files.}



\subsubsection{The result backend}
Since the worker generates files as results that get uploaded to the file server by the task itself, a result backend is only needed to keep track of the states of the tasks.
This implies that there is no big load on the result backend, and thus the same database as Django is using can be used, simplifying the setup.
One just has to make sure that external workers not running on the server machine can reach the database server\footnote{default mySQL configuration restricts access to connections from \T{localhost}}.




